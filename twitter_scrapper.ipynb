{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import pytz\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bearer tokens only 1st time when use the notebook\n",
    "# Delete it for security after comply it.\n",
    "#os.environ['TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth():\n",
    "    ''' Get TOKEN from os environment variables'''\n",
    "    return os.getenv(\"TOKEN\")\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    ''' Generate request header using bearer token'''\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "\n",
    "def create_url(keyword, start_date, end_date, max_results = 10):\n",
    "    '''\n",
    "    Reference fo search/all API endpoint\n",
    "    https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-all\n",
    "    '''\n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/all\" \n",
    "\n",
    "\n",
    "    '''\n",
    "    \"query\" : https://developer.twitter.com/en/docs/twitter-api/tweets/counts/integrate/build-a-query\n",
    "    \"tweet.fields\" : https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet\n",
    "    \"user.fields\" : https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user \n",
    "    \"place.fields\" : https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/place\n",
    "    '''\n",
    "\n",
    "    query_params = {'query': keyword,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
    "                    'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "                    'user.fields': 'id,name,username,created_at,description,location,public_metrics,verified',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}\n",
    "                    \n",
    "    return (search_url, query_params)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   # Use for seaching in next pages\n",
    "\n",
    "    # Make request to API\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "\n",
    "    # Check API response code\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credential Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credential initiate for Twitter API\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Dict Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Search Parameters\n",
    "Duration per keywords\n",
    "2022-03-01T00:00:00.000Z\n",
    "2017-01-01T00:00:00.000Z\n",
    "\n",
    "Hash tag list\n",
    "[\"#นัดเย็ดกทม\", \"#onsกทม\", \"#fwbกทม\", \"#นัดเย็ดกรุงเทพ\"]\n",
    "\n",
    "'''\n",
    "\n",
    "keyword = 'นัดเย็ดกรุงเทพ OR นัดเย็ดกรุงเทพ. OR #นัดเย็ดกรุงเทพ'\n",
    "start_time = \"2017-01-01T00:00:00.000Z\"\n",
    "end_time = \"2022-03-01T00:00:00.000Z\"\n",
    "max_results = 500\n",
    "\n",
    "# Create query dict for Twitter API\n",
    "url = create_url(keyword, start_time,end_time, max_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Request to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_tweet = pd.DataFrame()\n",
    "df_total_user = pd.DataFrame()\n",
    "\n",
    "end_search_set = True\n",
    "\n",
    "page_token = None\n",
    "while end_search_set:\n",
    "    # Make request to API\n",
    "    json_response = connect_to_endpoint(url[0], headers, url[1], page_token)\n",
    "\n",
    "    # Change json data into Pandas DataFrame\n",
    "    df_tweet_temp = pd.DataFrame(json_response['data']) \n",
    "    user_data_temp = pd.DataFrame(json_response[\"includes\"]['users']) \n",
    "\n",
    "    # ------------ Display Records per pages ------------ #\n",
    "    print(\"Pages token : \", page_token)\n",
    "    print(\"Tweet number on current page : \", len(df_tweet_temp))\n",
    "    print('---- *** ---- *** --- *** ---- *** --- ')\n",
    "    print(\"\")\n",
    "    # ------------ Display Records per pages ------------ #\n",
    "    \n",
    "    # Combine data from eacth request per page\n",
    "    df_total_tweet = df_total_tweet.append(df_tweet_temp)\n",
    "    df_total_user = df_total_user.append(user_data_temp)\n",
    "\n",
    "    if 'next_token' in json_response[\"meta\"]:\n",
    "        page_token = json_response[\"meta\"]['next_token']\n",
    "        time.sleep(5)\n",
    "    else:\n",
    "        end_search_set = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155584, 12)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115352, 8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(dataframe:pd.DataFrame, datetime_column:str) -> pd.DataFrame:\n",
    "    my_timezone = \"Asia/Bangkok\"\n",
    "    dataframe[datetime_column + \"_dt\"] = pd.to_datetime(dataframe[datetime_column])\n",
    "    dataframe[datetime_column +\"_time\"] = dataframe[datetime_column + \"_dt\"].dt.time\n",
    "    dataframe[datetime_column +\"_date\"] = dataframe[datetime_column + \"_dt\"].dt.date\n",
    "\n",
    "    dataframe[datetime_column + \"_dt_thtz\"] = dataframe[datetime_column + \"_dt\"].dt.tz_convert(my_timezone)\n",
    "    dataframe[datetime_column + \"_time_thtz\"] = dataframe[datetime_column + \"_dt_thtz\"].dt.time\n",
    "    dataframe[datetime_column + \"_date_thtz\"] = dataframe[datetime_column + \"_dt_thtz\"].dt.date\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conver datetime to Thailand timezone\n",
    "df_total_tweet = convert_datetime(df_total_tweet, \"created_at\")\n",
    "df_total_user = convert_datetime(df_total_user, \"created_at\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to .csv format with UTF-8 encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_tweet.to_csv(f\"{keyword}_{str(df_total_tweet['created_at_dt_thtz'].max())}_{str(df_total_tweet['created_at_dt_thtz'].min())}_tweetdata.csv\", encoding='utf-8-sig')\n",
    "df_total_user.to_csv(f\"{keyword}_{str(df_total_user['created_at_dt_thtz'].max())}_{str(df_total_user['created_at_dt_thtz'].min())}_userdata.csv\", encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c627cbd8298e61f5d807bd70e1856c0a810ac2c0c1e0e9c4e3a798bcc8e916d7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
